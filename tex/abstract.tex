%# -*- coding: utf-8-unix -*-
% !TEX program = xelatex
% !TEX root = ../thesis.tex
% !TEX encoding = UTF-8 Unicode
%%==================================================
%% abstract.tex for SJTU Master Thesis
%%==================================================

\begin{abstract}


\end{abstract}

\begin{englishabstract}
Traffic signal control is essential for transportation efficiency in the road network. It has been a challenging problem because of the complexity in traffic dynamics. Conventional transportation research suffers from the incompetency to adapt to dynamic traffic situations. Recent studies propose to use reinforcement learning (RL) to search for more efficient traffic signal plans. However, all existing RL-based studies design the key elements - reward and state - in a heuristic way. This results in highly sensitive performances and a long learning process.

To avoid heuristic design of RL for traffic signal control, we are the first to connect RL with recent studies in transportation research. Our method is inspired by the state-of-the-art method max pressure (MP) in the transportation field. The reward design of our method is well supported by the theory in MP, which can be proved to be maximizing the throughput of the traffic network, i.e., minimizing the overall network travel time. We also justify the concise state representation which can fully support the optimization of the proposed reward function. Through comprehensive experiments, we demonstrate that our method can outperform both conventional transportation approaches and existing learning-based methods.

====

Arterial streets serve as the principal undertaker for urban mobility in a typical urban road network. In this paper, we propose a novel decentralized reinforcement learning method for multi- intersection traffic signal control on arterial traffic, by applying reinforcement learning control agents in each intersection. While applying individual control to multi-intersection problems faces many challenges, two main adjustments are made to optimize the overall performance: 1) to provide simple yet novel contextual information to individual agents and 2) to train the RL agents in a transfer learning way. We test our method on both synthetic data and real-world dataset and show that our proposed method outperforms the state-of-the-art methods. We also interpret the policies learned by our method, which is the first time that the policy learned by the reinforcement learning control agents is interpreted using the traditional transportation coordination method on the arterial. 

=====

Traffic congestion plagues cities around the world. Recent years have witnessed an unprecedented trend on applying reinforcement learning for traffic signal control, both on individual level or region level. However, the utmost challenge is to control and coordinate traffic lights in large-scale two-dimensional urban networks. No one has ever tested RL models on a large-scale network of more than a thousand traffic lights. In this paper, we tackle the problem of multi-intersection traffic light control, especially for large-scale networks, based on RL techniques and traditional transportation theories. This problem is quite challenging because:(1) It is hard to theoretically justify the design of RL-based models in solving the multi-intersection control problem; (2) The action and state space would be increasing exponentially due to the curse of dimensionality for coordinated traffic light control approaches. To address these two challenges, we, (1) design and justify our RL agents using Max Pressure control theory and interpret the policy learned by Macroscopic Fundamental Diagrams from transportation field; (2) show that implicit coordination could be achieved by individual control agents with well-crafted reward design thus reducing the dimensionality; and (3) conduct extensive experiments on multiple scenarios, including a real-world scenario with 2510 traffic lights in Manhattan, New York City.

\end{englishabstract}

