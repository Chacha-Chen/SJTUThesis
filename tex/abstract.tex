%# -*- coding: utf-8-unix -*-
% !TEX program = xelatex
% !TEX root = ../thesis.tex
% !TEX encoding = UTF-8 Unicode
%%==================================================
%% abstract.tex for SJTU Master Thesis
%%==================================================

\begin{abstract}
交通信号控制对于道路网络中的交通效率至关重要。由于交通动态的复杂性，这一直是一个具有挑战性的问题。传统的交通研究受到不适应动态交通情况的困扰。最近的研究建议使用强化学习（RL）来搜索更有效的交通信号计划。

在典型的城市道路网络中，主干道是城市交通的主要承担者。在第一章中，我提出了一种新的分散的强化学习方法，用在每个交叉路口应用强化学习控制代理来进行多路口交通信号控制。虽然将分散的单独控制应用于多交叉问题面临许多挑战，但是我进行了两个主要调整以优化整体性能：1）向个体代理提供简单但新颖的状态信息;以及2）以转移学习方式训练RL代理。我在合成的数据和现实世界的数据集上测试了这种方法，并表明这种方法优于目前最先进的方法。我还尝试解释了这种方法所学到的政策，这是第一次使用传统的交通协调方法来说明强化学习控制代理所学到的政策。

然而，所有现有的基于RL的研究都以启发式方式设计关键要素--奖励和状态。这导致高度敏感的表现和漫长的学习过程。为了避免用于交通信号控制的RL的启发式设计，在第2章中，我将RL与最近的交通研究研究联系起来。该方法的灵感来传统交通领域中最先进的最大压力（MP）方法。MP中的理论支持这种方法的奖励设计，并可以证明这种奖励设计是在最大化路网的吞吐量，也即最小化所有车在整个网络中的旅行时间。我还证明了用简洁的状态表示可以完全支持所提出的奖励函数的优化。通过综合实验，我证明该方法可以胜过传统的交通方法和现有的基于学习的方法。


交通拥堵困扰着世界各地的城市。近年来，在个人或地区层面上应用强化学习进行交通信号控制的前所未有的趋势。最重要的是，最大的挑战是控制和协调大规模路网中的交通灯，特别是在有几千个交通灯的大型路网。在第3章中，我解决了多交叉口交通灯控制的问题，尤其是对于大规模网络。主要有两个挑战，（1）全局优化大规模路网下的交通灯目前是理论不可解的；（2）由于协调交通灯控制方法的维数诅咒，解决问题的难度呈指数级增长。为了解决这两个挑战，我们做出了三项主要贡献：（1）利用最大压力控制理论设计和证明这个RL代理，并解释交通领域宏观基本图学习的政策;（2）表明个体控制代理可以通过精心设计的奖励设计实现隐性协调，从而减少维度;（3）在多种情景下进行广泛的实验，包括一个基于纽约曼哈顿路网的包括2510交通灯的真实实验场景。

\end{abstract}

\begin{englishabstract}
Traffic signal control is essential for transportation efficiency in the road network. It has been a challenging problem because of the complexity in traffic dynamics. Conventional transportation research suffers from the incompetency to adapt to dynamic traffic situations. Recent studies propose to use reinforcement learning (RL) to search for more efficient traffic signal plans. 

Arterial streets serve as the principal undertaker for urban mobility in a typical urban road network. In chapter 1, I propose a novel decentralized reinforcement learning method for multi-intersection traffic signal control on arterial traffic, by applying reinforcement learning control agents in each intersection. While applying individual control to multi-intersection problems faces many challenges, two main adjustments are made to optimize the overall performance: 1) to provide simple yet novel contextual information to individual agents and 2) to train the RL agents in a transfer learning way. I test this method on both synthetic data and real-world dataset and show that this proposed method outperforms the state-of-the-art methods. I also interpret the policies learned by this method, which is the first time that the policy learned by the reinforcement learning control agents is interpreted using the traditional transportation coordination method on the arterial. 

However, all existing RL-based studies design the key elements - reward and state - in a heuristic way. This results in highly sensitive performances and a long learning process. To avoid heuristic design of RL for traffic signal control, in chapter 2 I connect RL with recent studies in transportation research. This method is inspired by the state-of-the-art method max pressure (MP) in the transportation field. The reward design of this method is Ill supported by the theory in MP, which can be proved to be maximizing the throughput of the traffic network, i.e., minimizing the overall network travel time. I also justify the concise state representation which can fully support the optimization of the proposed reward function. Through comprehensive experiments, I demonstrate that this method can outperform both conventional transportation approaches and existing learning-based methods.


Traffic congestion plagues cities around the world. Recent years have witnessed an unprecedented trend on applying reinforcement learning for traffic signal control, both on individual level or region level. HoIver, the utmost challenge is to control and coordinate traffic lights in large-scale two-dimensional urban networks. No one has ever tested RL models on a large-scale network of more than a thousand traffic lights. In chapter 3, I tackle the problem of multi-intersection traffic light control, especially for large-scale networks, based on RL techniques and traditional transportation theories. This problem is quite challenging because:(1) It is hard to theoretically justify the design of RL-based models in solving the multi-intersection control problem; (2) The action and state space would be increasing exponentially due to the curse of dimensionality for coordinated traffic light control approaches. To address these two challenges, 3 major contributions are made, (1) design and justify this RL agents using Max Pressure control theory and interpret the policy learned by Macroscopic Fundamental Diagrams from transportation field; (2) show that implicit coordination could be achieved by individual control agents with Ill-crafted reward design thus reducing the dimensionality; and (3) conduct extensive experiments on multiple scenarios, including a real-world scenario with 2510 traffic lights in Manhattan, New York City.

\end{englishabstract}

